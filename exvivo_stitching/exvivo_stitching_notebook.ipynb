{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d78793b6",
   "metadata": {},
   "source": [
    "# napari gui for manual matchings\n",
    "\n",
    "## what this is for \n",
    "this is for stitching problems. say we have two (or more) 3d images that are supposed to be next to each other (consecutive on z), and assume some cells in the first image can be seen in the second images. then we can use these cells to find the registration btw them. \n",
    "\n",
    "\n",
    "## features\n",
    "1. we can look into multiple channels (here we use 5 channels as an example)\n",
    "2. steps are: select the cells spots -> learn the scaling -> learn the affine -> learn the nonrigid transformation. all these steps require the cell centers that a user would select on own. \n",
    "\n",
    "## hot to use:\n",
    "to use this, we need to make sure the data files (tiff images) are organized in the way we want!  \n",
    "\n",
    "this notebook therefore does two things:\n",
    "\n",
    "1. load the data and arrange in the way we want -- this is necessary for us to load the channles correctly\n",
    "2. launch napari to do the manual registration and save the results.\n",
    "\n",
    "for how to load the results and then stitch the original images, that will be in the other notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369e21d9",
   "metadata": {},
   "source": [
    "# 0. setup the environment and define the functinos needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "862e0cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "070924\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "import tifffile\n",
    "import napari\n",
    "import os \n",
    "import glob\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import helpers\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(suppress=True)\n",
    "import scipy.ndimage as ndi\n",
    "from skimage.transform import warp\n",
    "from scipy.spatial import distance\n",
    "import math\n",
    "\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "todaystamp = today.strftime(\"%m%d%y\")\n",
    "print(todaystamp)\n",
    "\n",
    "import sys \n",
    "sys.path.append('../functions/')\n",
    "from transformations import wahba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae7d694",
   "metadata": {},
   "source": [
    "# 1. set up the directory. \n",
    "`file_dir` example:\n",
    "```\n",
    "!ls -lt /Users/shuonan/project/project_1/multimodal_experiments/data_from_jan_2024/tifs/ \n",
    "\n",
    "total 0\n",
    "drwx------@ 6 shuonanchen  staff  192 Feb 18 19:00 MERFISH_DAPI\n",
    "drwx------@ 6 shuonanchen  staff  192 Feb 18 18:59 MERFISH_GCaMP\n",
    "drwx------@ 6 shuonanchen  staff  192 Feb 18 18:59 MERFISH_polyA\n",
    "drwx------@ 6 shuonanchen  staff  192 Feb 17 16:13 MERFISH_tdTomato_G126\n",
    "drwx------@ 7 shuonanchen  staff  224 Feb 17 16:13 MERFISH_BV_G126\n",
    "```\n",
    "\n",
    "**note that `file_dir` should be the names of the channels. if you have only one channel then it should be the folder of all the tif images**\n",
    "for example, say your 6 sections of exvivo are stored in here: `Users/your_name/project/experiment_data/data_from_jan_2024/images/` and each of them have a name `mouse_10_section_1`, `mouse_10_section_2`, `mouse_10_section_3`,,,   \n",
    "\n",
    "then your `file_dir` must be `Users/your_name/project/experiment_data/data_from_jan_2024/` but not `Users/your_name/project/experiment_data/data_from_jan_2024/images/ `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeb43f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is where the results will be saved. \n",
    "base_dir = '/path_to_downloadfile/napari_rez/'\n",
    "\n",
    "# this is where the files are located. \n",
    "file_dir = '/path_to_downloadfile/tifs/'\n",
    "print(file_dir)  # again this should show you a list of channel-specific folders. each folder have one tif for one section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd26c90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tdTomato', 'BV', 'DAPI', 'GCaMP', 'polyA']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_channel_files = glob.glob(file_dir+'/*')  # this should be the list of the channel-speficif folders. \n",
    "channel_name = [f.split('/')[-1].split('_')[1] for f in all_channel_files]\n",
    "print(channel_name)  # these are all the available channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4454b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify how many (or which) channels you want to load. \n",
    "C = len(channel_name) # if loading all the channels. \n",
    "C = 1  # by default we can assume there is only one channel you are using to stitch. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35673f21",
   "metadata": {},
   "source": [
    "# 2. load and arrange the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "778392ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "exvivos = []\n",
    "exvivos.append(np.nan)  # this is to make it consistent -- exvivos[0] is nothing, since the section_id starts from 1.\n",
    "for section_id in range(1,5):  # only looking at section 1,2,3,4. \n",
    "    all_channels_img = []\n",
    "    for f in all_channel_files:  # f is the folder for this channel. \n",
    "        f_path = glob.glob(f+f'/*section{section_id}.tif*')\n",
    "        assert(len(f_path)==1)\n",
    "        f_path = f_path[0]\n",
    "        img = tifffile.imread(f_path)\n",
    "        img = img.astype(float)\n",
    "        img /= img.max()\n",
    "        all_channels_img.append(img)  # these should all be the same sizes. \n",
    "    exvivos.append(np.stack(all_channels_img, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcf3a9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exvivos)  # this should be 5 == 4+1 (1 is the nan part, 4 is the number of sections we are looking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d6ca4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 8, 2241, 2740),\n",
       " (2, 8, 2241, 2741),\n",
       " (2, 8, 2645, 2943),\n",
       " (2, 8, 2645, 2943)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the size of each\n",
    "[m.shape for m in exvivos[1:]]  # these are (c,z,x,y) where c is the number of channel (1), z should be number of zslices you took for each section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8741f0",
   "metadata": {},
   "source": [
    "**okay the data is ready, now we are ready to launch the GUI.**\n",
    "# 3. launch GUI\n",
    "- notes\n",
    "    - only look a pair at a time\n",
    "    - dont forget to save (`q`)\n",
    "- how to use\n",
    "    1. select `section_id`: if `section_id=1`, then section 1 (red) and 2 (green) will be loaded. the larger index is always the source, mapped to the smaller one. (2 is transformed to map 1).\n",
    "    2. focus on BV layer, adjust the gamma and contrast. hide the ohter channels when necessary.\n",
    "    3. go to the `matched` layer, add points in both green and red. Note the number of points in green and red must be the same. \n",
    "    4. do the necessary transformation until you are bored with these layer (BV), then swtich to the tomato layer (hide BV, show tomato)\n",
    "    5. you can clean the selected, or add more spots based on the tomato layer. \n",
    "    6. check the console output (from this notebook) for the necessary informations. \n",
    "    7. the saved results would contain (1) all the transformations applied; and (2) transformed image. \n",
    "- keys (in the using order)\n",
    "    - `s`: scaling --> learn the scale and adjust the images \n",
    "    - `t`: transform --> rigid transformation\n",
    "    - `c`: clear --> clear all selection of matched points. \n",
    "    - `d`: deformable --> apply deformable for the matched points.\n",
    "    - `q`: quit --> well it doesnt quit the gui, it just save the results so dont press this unless you are done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b044a699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose your section_id\n",
    "section_id = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53d3ee40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying rigid..\n",
      "learning scale..\n",
      "scale difference: 0.9982306505448446\n",
      "applying rigid..\n",
      "learning scale..\n",
      "scale difference: 1.0020945622556776\n",
      "applying rigid..\n",
      "applying rigid..\n",
      "applying deformable..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = {'label': np.empty(0, dtype=int)}\n",
    "all_transform = []\n",
    "viewer = napari.view_image(exvivos[section_id][:,0],channel_axis=0,\n",
    "                           contrast_limits=(0,exvivos[section_id][:,-1].max()), blending = 'additive',\n",
    "                           name=[f'sec {section_id+11}...{c}' for c in channel_name],\n",
    "                           colormap='red', visible = [True,True,False,False,False],)\n",
    "exvivo_layer = viewer.add_image(exvivos[section_id+1][:,-1],channel_axis=0,\n",
    "                                contrast_limits=(0,exvivos[section_id+1][:,-1].max()), blending = 'additive',\n",
    "                                name=[f'sec {section_id+12}...{c}' for c in channel_name],\n",
    "                                colormap=\"green\", visible = [True,True,False,False,False],)\n",
    "pl_in = viewer.add_points(\n",
    "    size=5, edge_width=1, edge_color='red',face_color='transparent',    \n",
    "    name=f\"matched section {section_id}\", text='label', features=features,ndim=2,out_of_slice_display=True)\n",
    "@pl_in.events.data.connect\n",
    "def update_feature_default_invivo():  \n",
    "    global points_layer\n",
    "    no_of_points = len(pl_in.data)\n",
    "    pl_in.feature_defaults['label'] = no_of_points + 1\n",
    "    pl_in.properties[\"label\"][0:no_of_points] = range(1, no_of_points+1)\n",
    "    pl_in.text.values[0:no_of_points] = [str(i) for i in range(1, no_of_points+1)]\n",
    "    pl_in.text.color = 'red'\n",
    "    pl_in.text.translation = np.array([-10, 0])\n",
    "update_feature_default_invivo()\n",
    "pl_in.mode = 'add'\n",
    "\n",
    "pl_ex = viewer.add_points(\n",
    "    size=5, edge_width=1, edge_color='green',face_color='transparent',    \n",
    "    name=f\"matched section {section_id+1}\", text='label', features=features,ndim=2,out_of_slice_display=True)\n",
    "@pl_ex.events.data.connect\n",
    "def update_feature_default_exvivo():  \n",
    "    global points_layer\n",
    "    no_of_points = len(pl_ex.data)\n",
    "    pl_ex.feature_defaults['label'] = no_of_points + 1\n",
    "    pl_ex.properties[\"label\"][0:no_of_points] = range(1, no_of_points+1)\n",
    "    pl_ex.text.values[0:no_of_points] = [str(i) for i in range(1, no_of_points+1)]\n",
    "    pl_ex.text.color = 'green'\n",
    "    pl_ex.text.translation = np.array([-10, 0])\n",
    "update_feature_default_exvivo()\n",
    "pl_ex.mode = 'add'\n",
    "\n",
    "@viewer.bind_key('s', overwrite = True)\n",
    "def scale(viewer):  \n",
    "    print('learning scale..')\n",
    "    m_invivo = viewer.layers[f\"matched section {section_id}\"].data\n",
    "    m_exvivo = viewer.layers[f\"matched section {section_id+1}\"].data \n",
    "    assert(len(m_invivo)==len(m_exvivo))    \n",
    "    s_invivo = np.sqrt(np.sum((m_invivo-np.mean(m_invivo,0))**2)/len(m_invivo))\n",
    "    s_exvivo = np.sqrt(np.sum((m_exvivo-np.mean(m_exvivo,0))**2)/len(m_exvivo))\n",
    "    scl = s_invivo/s_exvivo\n",
    "    print(f'scale difference: {scl}')\n",
    "    m_exvivo_new = scl*m_exvivo    \n",
    "    exvivo_scaled_small = np.array([ndi.zoom(exvivo_layer[c].data, scl, order=3) for c in range(C)])    \n",
    "    all_transform.append(dict(scale=scl))\n",
    "    for c in range(C):\n",
    "        exvivo_layer[c].data = exvivo_scaled_small[c]\n",
    "    viewer.layers[f\"matched section {section_id+1}\"].data = m_exvivo_new    \n",
    "    \n",
    "\n",
    "@viewer.bind_key('t', overwrite = True)\n",
    "def transform(viewer):    \n",
    "    print('applying rigid..')\n",
    "    m_invivo = viewer.layers[f\"matched section {section_id}\"].data\n",
    "    m_exvivo = viewer.layers[f\"matched section {section_id+1}\"].data\n",
    "    assert(len(m_invivo)==len(m_exvivo))\n",
    "    bhat = wahba(m_exvivo,m_invivo)\n",
    "    offset = -(bhat[:2,:2])@bhat[-1]\n",
    "    exvivo_affined = np.array([ndi.affine_transform(exvivo_layer[c].data, bhat[:2,:2],\n",
    "                                                    output_shape = exvivo_layer[0].data.shape,offset = offset, order=3) for c in range(C)])\n",
    "    foo = np.c_[m_exvivo, np.ones((m_exvivo.shape[0],1))]   #Nx4\n",
    "    m_exvivo_update = foo@bhat\n",
    "    all_transform.append(dict(bhat=bhat))\n",
    "    for c in range(C):\n",
    "        exvivo_layer[c].data = exvivo_affined[c]\n",
    "    viewer.layers[f\"matched section {section_id+1}\"].data = m_exvivo_update\n",
    "\n",
    "    \n",
    "@viewer.bind_key('d', overwrite = True)\n",
    "def deform(viewer):    \n",
    "    print('applying deformable..')\n",
    "    ksz = 200\n",
    "    m_invivo = viewer.layers[f\"matched section {section_id}\"].data\n",
    "    m_exvivo = viewer.layers[f\"matched section {section_id+1}\"].data\n",
    "    assert(len(m_invivo)==len(m_exvivo))    \n",
    "    shift = m_invivo-m_exvivo   # so the newcoords = old+shift --> vecfield will have how much shift needed to apply to the old coords\n",
    "    vec_field = np.zeros(exvivo_layer[0].data.shape + (2,))  # M1,M2,2\n",
    "    for p,loc in enumerate(m_exvivo):\n",
    "        vec_field[int(loc[0]),int(loc[1])] = shift[p]\n",
    "    for c in range(C):\n",
    "        vec_field[...,c] = ndi.gaussian_filter(vec_field[...,c], ksz)\n",
    "    A = np.zeros_like(m_exvivo)\n",
    "    for p,loc in enumerate(m_exvivo):\n",
    "        A[p] = vec_field[int(loc[0]),int(loc[1])]\n",
    "    diag_step,_,_,_ = np.linalg.lstsq(A,shift,rcond=None)\n",
    "    step = np.diag(diag_step)\n",
    "    vec_field_total =vec_field*step;  # element wise. \n",
    "    all_transform.append(dict(vec_field_total=vec_field_total))\n",
    "    mapx_base, mapy_base = np.meshgrid(np.arange(exvivo_layer[0].data.shape[0]),np.arange(exvivo_layer[0].data.shape[1]), indexing='ij')\n",
    "    mapx=mapx_base-vec_field_total[:,:,0]\n",
    "    mapy=mapy_base-vec_field_total[:,:,1]\n",
    "    for c in range(C):\n",
    "        img_de = warp(exvivo_layer[c].data,np.array((mapx,mapy)), order = 3)            \n",
    "        exvivo_layer[c].data = img_de    \n",
    "    \n",
    "    m_exvivo_new = np.zeros_like(m_exvivo)  # POINTS\n",
    "    for p,loc in enumerate(m_exvivo):\n",
    "        new_s = vec_field_total[int(loc[0]),int(loc[1])]\n",
    "        m_exvivo_new[p] = loc+new_s\n",
    "    viewer.layers[f\"matched section {section_id+1}\"].data = m_exvivo_new\n",
    "    \n",
    "@viewer.bind_key('c')\n",
    "def clear_selected(viewer):        \n",
    "    viewer.layers[f\"matched section {section_id}\"].data = np.empty((0, 2))\n",
    "    viewer.layers[f\"matched section {section_id+1}\"].data = np.empty((0, 2))\n",
    "\n",
    "    \n",
    "@viewer.bind_key('q')\n",
    "def save_rez(viewer):     \n",
    "    out_dict = dict()\n",
    "    out = np.array([exvivo_layer[c].data for c in range(C)] )\n",
    "    out_dict[f'transformed_section_{section_id+1}']=out\n",
    "    out_dict['transformations']=all_transform    \n",
    "    pickle.dump(out_dict, open(base_dir + f'section_{section_id}_{section_id+1}_{todaystamp}.pkl','wb'))\n",
    "    print(\"saved the results!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "457bb0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'022123'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todaystamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada147eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa38b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762b1034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv2",
   "language": "python",
   "name": "cv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
